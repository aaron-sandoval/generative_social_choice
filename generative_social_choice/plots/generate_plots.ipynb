{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import scipy\n",
    "from generative_social_choice.utils.helper_functions import get_base_dir_path\n",
    "from generative_social_choice.slates.voting_utils import gini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likert_scores: dict[int, str] = {\n",
    "#     0: \"Very poorly\",\n",
    "#     1: \"Poorly\",\n",
    "#     2: \"Moderately\",\n",
    "#     3: \"Well\",\n",
    "#     4: \"Very well\",\n",
    "#     5: \"Excellently\",\n",
    "#     6: \"Exceptionally\",\n",
    "# }\n",
    "# v3.alpha chatbot personalization Likert scale\n",
    "likert_scores: dict[int, str] = {\n",
    "    0: \"Not at all\",\n",
    "    1: \"Poorly\",\n",
    "    2: \"Somewhat\",\n",
    "    3: \"Mostly\",\n",
    "    4: \"Perfectly\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "likert_scores_reverse: dict[str, int] = {v: k for k, v in likert_scores.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_social_choice.utils.helper_functions import get_results_paths\n",
    "\n",
    "LABELLING_MODEL = \"4o-mini\"\n",
    "EMBEDDING_TYPE = \"seed_statement\"\n",
    "\n",
    "baseline_result_dirs = get_results_paths(labelling_model=LABELLING_MODEL, baseline=True)\n",
    "result_dirs = get_results_paths(labelling_model=LABELLING_MODEL, embedding_type=EMBEDDING_TYPE, baseline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_assignments_file_path = baseline_result_dirs[\"assignments\"]\n",
    "\n",
    "with open(baseline_assignments_file_path, \"r\") as f:\n",
    "    baseline_assignment_data = (json.load(f))\n",
    "\n",
    "\n",
    "baseline_assignment_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with assignments and utilities\n",
    "baseline_assignments = pd.DataFrame({\n",
    "    'candidate_id': baseline_assignment_data['assignments'],\n",
    "    'utility': baseline_assignment_data['utilities']\n",
    "}, index=baseline_assignment_data['agent_ids'])\n",
    "baseline_assignments.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo_assignment_files = {\n",
    "#     \"Exact Total\": data_dir_path / \"assignments\" / \"exact.json\",\n",
    "#     \"Greedy Total\": data_dir_path / \"assignments\" / \"greedy.json\",\n",
    "#     \"LP Total\": data_dir_path / \"assignments\" / \"lp.json\",\n",
    "#     \"Phragmen\": data_dir_path / \"assignments\" / \"phragmen.json\",\n",
    "# }\n",
    "algo_assignment_files = {\n",
    "    path.stem: path for path in (result_dirs[\"assignments\"]).glob(\"*.json\")\n",
    "}\n",
    "\n",
    "utilities = pd.DataFrame(columns=[\"Baseline\"] + list(algo_assignment_files.keys()), index=baseline_assignments.index)\n",
    "utilities[\"Baseline\"] = baseline_assignments[\"utility\"]\n",
    "\n",
    "assignments = pd.DataFrame(columns=[\"Baseline\"] + list(algo_assignment_files.keys()), index=baseline_assignments.index)\n",
    "assignments[\"Baseline\"] = baseline_assignments[\"candidate_id\"]\n",
    "\n",
    "for algo_name, file_path in algo_assignment_files.items():\n",
    "    with open(file_path, \"r\") as f:\n",
    "        algo_assignment_data = (json.load(f))\n",
    "        algo_utilities = pd.Series(algo_assignment_data['utilities'], index=algo_assignment_data['agent_ids'])\n",
    "        utilities[algo_name] = algo_utilities\n",
    "        algo_assignments = pd.Series(algo_assignment_data['assignments'], index=algo_assignment_data['agent_ids'])\n",
    "        assignments[algo_name] = algo_assignments\n",
    "\n",
    "\n",
    "\n",
    "utilities.head(), assignments.head()\n",
    "\n",
    "\n",
    "# all_algorithm_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots & Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proportion_confidence_intervals(counts: np.ndarray, total: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate confidence intervals for proportions, including exact calculation for small counts where the normal approximation is not valid.\n",
    "    \"\"\"\n",
    "    proportions = counts / total\n",
    "    nqp = counts * proportions\n",
    "    standard_errors = np.sqrt(proportions * (1 - proportions) / total)\n",
    "    \n",
    "    # Initialize bounds with normal approximation\n",
    "    lower_bounds = np.maximum(0, proportions - standard_errors)\n",
    "    upper_bounds = np.minimum(1, proportions + standard_errors)\n",
    "    \n",
    "    # Identify indices where exact calculation is needed\n",
    "    exact_indices = nqp < 5\n",
    "    \n",
    "    # Exact binomial calculation for nqp < 5\n",
    "    if np.any(exact_indices):\n",
    "        exact_lower = scipy.stats.binom.ppf(0.025, total, proportions[exact_indices]) / total\n",
    "        exact_upper = scipy.stats.binom.ppf(0.975, total, proportions[exact_indices]) / total\n",
    "        lower_bounds[exact_indices] = exact_lower\n",
    "        upper_bounds[exact_indices] = exact_upper\n",
    "    \n",
    "    return np.vstack((lower_bounds, proportions, upper_bounds)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline-only plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likert_category_bar_chart(assignments: pd.DataFrame) -> plt.figure:\n",
    "    \"\"\"\n",
    "    Bar chart of the distribution of likert scores with error bars.\n",
    "\n",
    "    Utilities are rounded to the nearest integer and mapped to the likert scale.\n",
    "    Bars are sequenced from lowest to highest likert score.\n",
    "    The y axis is the percentage of the sample that received each score.\n",
    "    Error bars represent the standard error of the proportion.\n",
    "    \"\"\"\n",
    "    # Round utilities and map to likert scores\n",
    "    assignments[\"utility\"] = assignments[\"utility\"].round().astype(int)\n",
    "    assignments[\"likert_score\"] = assignments[\"utility\"].map(likert_scores)\n",
    "    \n",
    "    # Calculate counts\n",
    "    total = len(assignments)\n",
    "    counts = assignments[\"likert_score\"].value_counts().sort_index()\n",
    "\n",
    "    confidence_intervals = calculate_proportion_confidence_intervals(counts.values, total)\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    plot_data = pd.DataFrame({\n",
    "        \"likert_score\": counts.index,\n",
    "        \"proportion\": confidence_intervals[:, 1],\n",
    "        \"lower_bound\": confidence_intervals[:, 0],\n",
    "        \"upper_bound\": confidence_intervals[:, 2]\n",
    "    }).sort_values(\"likert_score\")\n",
    "\n",
    "    # Sort the plot data by likert score using the reverse mapping\n",
    "    plot_data = plot_data.sort_values(\n",
    "        \"likert_score\", \n",
    "        key=lambda x: x.map(likert_scores_reverse)\n",
    "    )\n",
    "    \n",
    "    # Convert proportions to percentages for plotting\n",
    "    plot_data[\"percentage\"] = plot_data[\"proportion\"] * 100\n",
    "    plot_data[\"lower_bound_percentage\"] = plot_data[\"lower_bound\"] * 100\n",
    "    plot_data[\"upper_bound_percentage\"] = plot_data[\"upper_bound\"] * 100\n",
    "    \n",
    "    yerr = np.array([\n",
    "        plot_data[\"percentage\"] - plot_data[\"lower_bound_percentage\"],\n",
    "        plot_data[\"upper_bound_percentage\"] - plot_data[\"percentage\"]\n",
    "    ])\n",
    "    \n",
    "    # Create figure and axis objects explicitly\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = ax.bar(\n",
    "        x=range(len(plot_data)),\n",
    "        height=plot_data[\"percentage\"],\n",
    "        yerr=yerr,\n",
    "        capsize=5\n",
    "    )\n",
    "    \n",
    "    # Customize x-axis\n",
    "    ax.set_xticks(range(len(plot_data)))\n",
    "    ax.set_xticklabels(\n",
    "        plot_data[\"likert_score\"],\n",
    "        # rotation=45 if len(plot_data) > 4 else 0\n",
    "    )\n",
    "    \n",
    "    # Customize y-axis\n",
    "    ax.set_ylabel(\"Percentage of Population (%)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# fig = plot_likert_category_bar_chart(baseline_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial vs Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_metrics = pd.DataFrame(index=utilities.columns, columns=[\"Avg_Utility\", \"Min_Utility\", r\"25th_Pctile_Utility\", \"Gini\"])\n",
    "\n",
    "scalar_metrics.Avg_Utility = utilities.mean(0).T\n",
    "scalar_metrics.Min_Utility = utilities.min(0).T\n",
    "scalar_metrics[\"25th_Pctile_Utility\"] = utilities.quantile(0.25, axis=0).T\n",
    "# Calculate Gini coefficient using scipy's implementation\n",
    "\n",
    "scalar_metrics.Gini = utilities.apply(lambda x: gini(x))\n",
    "\n",
    "scalar_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likert_category_clustered_bar_chart(\n",
    "    utilities: pd.DataFrame,\n",
    "    labels: dict[str, str] | None = None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Clustered bar chart comparing the distribution of likert scores across multiple\n",
    "    datasets with error bars.\n",
    "\n",
    "    Args:\n",
    "        utilities: DataFrame where each column contains utilities for a different\n",
    "            dataset/condition\n",
    "        labels: Optional dictionary mapping column names to display labels. If not\n",
    "            provided, uses the column names directly.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib Figure object containing the plot\n",
    "    \"\"\"\n",
    "    # Process each dataset/column\n",
    "    plot_data_dict = {}\n",
    "    for column in utilities.columns:\n",
    "        # Round utilities and map to likert scores\n",
    "        df = pd.DataFrame({\"utility\": utilities[column]}).copy()\n",
    "        df[\"utility\"] = df[\"utility\"].round().astype(int)\n",
    "        df[\"likert_score\"] = df[\"utility\"].map(likert_scores)\n",
    "        \n",
    "        # Calculate counts and proportions\n",
    "        total = len(df)\n",
    "        counts = df[\"likert_score\"].value_counts().sort_index()\n",
    "        \n",
    "        # Calculate confidence intervals\n",
    "        confidence_intervals = calculate_proportion_confidence_intervals(\n",
    "            counts.values, \n",
    "            total\n",
    "        )\n",
    "        \n",
    "        # Create DataFrame for this dataset\n",
    "        plot_data = pd.DataFrame({\n",
    "            \"likert_score\": counts.index,\n",
    "            \"proportion\": confidence_intervals[:, 1],\n",
    "            \"lower_bound\": confidence_intervals[:, 0],\n",
    "            \"upper_bound\": confidence_intervals[:, 2]\n",
    "        })\n",
    "        \n",
    "        # Sort by likert score\n",
    "        plot_data = plot_data.sort_values(\n",
    "            \"likert_score\", \n",
    "            key=lambda x: x.map(likert_scores_reverse)\n",
    "        )\n",
    "        \n",
    "        # Convert to percentages\n",
    "        plot_data[\"percentage\"] = plot_data[\"proportion\"] * 100\n",
    "        plot_data[\"lower_bound_percentage\"] = plot_data[\"lower_bound\"] * 100\n",
    "        plot_data[\"upper_bound_percentage\"] = plot_data[\"upper_bound\"] * 100\n",
    "        \n",
    "        plot_data_dict[column] = plot_data\n",
    "\n",
    "    # Set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate bar positions\n",
    "    n_datasets = len(utilities.columns)\n",
    "    bar_width = 0.8 / n_datasets  # Adjust total width of group\n",
    "    \n",
    "    # Get unique sorted likert scores across all datasets\n",
    "    all_scores = sorted(\n",
    "        set().union(*[df[\"likert_score\"] for df in plot_data_dict.values()]),\n",
    "        key=lambda x: likert_scores_reverse[x]\n",
    "    )\n",
    "    x = np.arange(len(all_scores))\n",
    "    \n",
    "    # Plot bars for each dataset\n",
    "    for i, (column, plot_data) in enumerate(plot_data_dict.items()):\n",
    "        # Calculate bar positions\n",
    "        offset = (i - (n_datasets - 1) / 2) * bar_width\n",
    "        x_pos = x + offset\n",
    "        \n",
    "        # Ensure data exists for all scores\n",
    "        heights = []\n",
    "        yerr = [[], []]\n",
    "        for score in all_scores:\n",
    "            score_data = plot_data[plot_data[\"likert_score\"] == score]\n",
    "            if len(score_data) > 0:\n",
    "                heights.append(score_data[\"percentage\"].iloc[0])\n",
    "                yerr[0].append(\n",
    "                    score_data[\"percentage\"].iloc[0] - \n",
    "                    score_data[\"lower_bound_percentage\"].iloc[0]\n",
    "                )\n",
    "                yerr[1].append(\n",
    "                    score_data[\"upper_bound_percentage\"].iloc[0] - \n",
    "                    score_data[\"percentage\"].iloc[0]\n",
    "                )\n",
    "            else:\n",
    "                heights.append(0)\n",
    "                yerr[0].append(0)\n",
    "                yerr[1].append(0)\n",
    "        \n",
    "        # Plot bars\n",
    "        label = labels[column] if labels else column\n",
    "        ax.bar(\n",
    "            x_pos,\n",
    "            heights,\n",
    "            bar_width,\n",
    "            yerr=yerr,\n",
    "            capsize=5,\n",
    "            label=label\n",
    "        )\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_ylabel(\"Percentage of Population (%)\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(all_scores)\n",
    "    ax.yaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_likert_category_clustered_bar_chart(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sorted_utility_distributions(utilities: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot sorted utility distributions for each column in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        utilities: DataFrame where each column contains utilities for different\n",
    "            methods/conditions\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib Figure object containing the plot\n",
    "    \"\"\"\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot each column's sorted distribution\n",
    "    for column in utilities.columns:\n",
    "        sorted_values = utilities[column].sort_values(ascending=False).values\n",
    "        indices = np.arange(len(sorted_values))\n",
    "        ax.plot(indices, sorted_values, label=column, color=plt.cm.tab20(utilities.columns.get_loc(column)))\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Voter index (sorted by utility)\")\n",
    "    ax.set_ylabel(\"Utility\")\n",
    "    ax.grid(axis='both', linestyle='--', alpha=0.7)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_sorted_utility_distributions(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_candidate_distribution_stacked(assignments: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart showing the distribution of candidate assignments.\n",
    "    Each stack represents a different method/condition, with bars stacked by\n",
    "    frequency of candidate assignment in descending order.\n",
    "\n",
    "    Args:\n",
    "        assignments: DataFrame where each column contains candidate assignments for\n",
    "            different methods/conditions\n",
    "\n",
    "    Returns:\n",
    "        matplotlib Figure object containing the plot\n",
    "    \"\"\"\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Get all unique candidates across all columns, sorted by name\n",
    "    all_candidates = sorted(set().union(*[\n",
    "        set(assignments[col].unique()) for col in assignments.columns\n",
    "    ]))\n",
    "    \n",
    "    # Process each column\n",
    "    x_positions = np.arange(len(assignments.columns))\n",
    "    max_height = 0\n",
    "    \n",
    "    for i, column in enumerate(assignments.columns):\n",
    "        # Count occurrences of each candidate\n",
    "        counts = assignments[column].value_counts()\n",
    "        sorted_counts = counts.sort_values(ascending=True)\n",
    "        \n",
    "        # Plot stacked bars\n",
    "        bottom = 0\n",
    "        for candidate, count in sorted_counts.items():\n",
    "            ax.bar(\n",
    "                i,\n",
    "                count,\n",
    "                bottom=bottom,\n",
    "                label=candidate if i == 0 else \"\",\n",
    "                width=0.8,\n",
    "                # Use same color for same candidate across stacks\n",
    "                color=plt.cm.tab20(all_candidates.index(candidate) % 20)\n",
    "            )\n",
    "            bottom += count\n",
    "        \n",
    "        max_height = max(max_height, bottom)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_ylabel(\"Number of Voters\")\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(assignments.columns, rotation=45, ha='right')\n",
    "    ax.yaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create custom legend handles and labels for all candidates\n",
    "    handles = [plt.Rectangle((0,0),1,1, \n",
    "                           color=plt.cm.tab20(i % 20)) \n",
    "              for i in range(len(all_candidates))]\n",
    "    \n",
    "    # Add legend outside the plot with all candidates\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        all_candidates,\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc='upper left',\n",
    "        title=\"Candidates\"\n",
    "    )\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_candidate_distribution_stacked(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from generative_social_choice.utils.postprocessing import (\n",
    "    plot_sorted_utility_distributions,\n",
    "    scalar_utility_metrics,\n",
    "    plot_candidate_distribution_stacked,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "from generative_social_choice.utils.helper_functions import get_results_paths\n",
    "from generative_social_choice.utils.postprocessing import plot_sorted_utility_CIs\n",
    "from generative_social_choice.ratings.utility_matrix import get_baseline_generate_slate_results\n",
    "\n",
    "\n",
    "def get_results(labelling_model: str, run_id: str, embedding_type: str = \"llm\"):\n",
    "    result_paths = get_results_paths(labelling_model=labelling_model, baseline=False,  embedding_type=embedding_type, run_id=run_id)\n",
    "\n",
    "    algo_assignment_result_dir = result_paths[\"assignments\"]\n",
    "    algo_assignment_files = {\n",
    "        path.stem: path for path in algo_assignment_result_dir.glob(\"*.json\")\n",
    "    }\n",
    "\n",
    "    algo_assignments = pd.DataFrame(columns=list(algo_assignment_files.keys())) #, index=baseline_assignments.index)\n",
    "    utilities = pd.DataFrame(columns=list(algo_assignment_files.keys()))\n",
    "\n",
    "    for algo_name, file_path in algo_assignment_files.items():\n",
    "        with open(file_path, \"r\") as f:\n",
    "            algo_assignment_data = (json.load(f))\n",
    "            algo_utilities = pd.Series(algo_assignment_data['utilities'], index=algo_assignment_data['agent_ids'])\n",
    "            utilities[algo_name] = algo_utilities\n",
    "            cur_algo_assignments = pd.Series(algo_assignment_data['assignments'], index=algo_assignment_data['agent_ids'])\n",
    "            algo_assignments[algo_name] = cur_algo_assignments\n",
    "\n",
    "\n",
    "    #algo_assignments.head()\n",
    "    #utilities.head()\n",
    "    return utilities, algo_assignments\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResultConfig:\n",
    "    name: str\n",
    "    embedding_type: str\n",
    "    run_ids: list[str]\n",
    "    labelling_model: str = \"4o-mini\"\n",
    "    pipeline: Literal[\"ours\", \"fish\"] = \"ours\"\n",
    "\n",
    "\n",
    "def show_results(configs: list[ResultConfig], method: str) -> tuple[dict[str, pd.DataFrame], dict[str, pd.DataFrame], dict[str, pd.DataFrame]]:\n",
    "    utility_dfs = {}\n",
    "    performance_dfs = {}\n",
    "    all_algo_assignments = {}\n",
    "    pipelines = {}\n",
    "\n",
    "    for config in configs:\n",
    "        # Collect metrics for all runs\n",
    "        all_metrics = []\n",
    "        config_algo_assignments = []\n",
    "        all_utilities = []\n",
    "        pipelines[config.name] = config.pipeline\n",
    "\n",
    "        if config.pipeline==\"fish\":\n",
    "            utilities, algo_assignments = get_baseline_generate_slate_results(run_ids=config.run_ids, embedding_type=config.embedding_type)\n",
    "\n",
    "            utility_dfs[config.name] = [utilities[col] for col in utilities.columns]\n",
    "            all_algo_assignments[config.name] = [algo_assignments[col] for col in algo_assignments.columns]\n",
    "            metrics_df = scalar_utility_metrics(utilities)\n",
    "        else:\n",
    "            for run_id in config.run_ids:\n",
    "                utilities, algo_assignments = get_results(labelling_model=config.labelling_model, run_id=run_id, embedding_type=config.embedding_type)\n",
    "                metrics = scalar_utility_metrics(utilities)\n",
    "                all_metrics.append(metrics.loc[method])\n",
    "                config_algo_assignments.append(algo_assignments)\n",
    "                all_utilities.append(utilities)\n",
    "\n",
    "            # Convert to DataFrame for easier analysis\n",
    "            metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "            utility_dfs[config.name] = all_utilities\n",
    "\n",
    "            all_algo_assignments[config.name] = config_algo_assignments\n",
    "\n",
    "        # Calculate mean and 95% confidence intervals\n",
    "        mean_metrics = metrics_df.mean()\n",
    "        std_metrics = metrics_df.std()\n",
    "        ci_95 = 1.96 * std_metrics / np.sqrt(len(config.run_ids))\n",
    "\n",
    "        # Create summary DataFrame with mean and confidence intervals\n",
    "        performance_summary = pd.DataFrame({\n",
    "            'Mean': mean_metrics,\n",
    "            '95% CI Lower': mean_metrics - ci_95,\n",
    "            '95% CI Upper': mean_metrics + ci_95\n",
    "        })\n",
    "        performance_dfs[config.name] = performance_summary\n",
    "\n",
    "    # Combine utilities for the selected method across all runs with MultiIndex columns\n",
    "    utilities_for_CI = pd.DataFrame({\n",
    "        (name, i): utility_dfs[name][i][method] if pipelines[name] == \"ours\" else utility_dfs[name][i]\n",
    "        for name in utility_dfs.keys()\n",
    "        #for i in (range(len(utility_dfs[name])) if pipelines[name] == \"ours\" else range(len(utility_dfs[name].columns)))\n",
    "        for i in range(len(utility_dfs[name]))\n",
    "    })\n",
    "    utilities_for_CI.columns = pd.MultiIndex.from_tuples(utilities_for_CI.columns)\n",
    "\n",
    "    # Now plot with CIs\n",
    "    plot_sorted_utility_CIs(utilities_for_CI)\n",
    "\n",
    "    return performance_dfs, utility_dfs, all_algo_assignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "METHOD = \"exact\"\n",
    "\n",
    "result_configs = [\n",
    "    ResultConfig(\n",
    "        name=\"Ours (LLM Embeddings)\",\n",
    "        embedding_type=\"llm\",\n",
    "        run_ids=list(range(10)),\n",
    "    ),\n",
    "    ResultConfig(\n",
    "        name=\"Ours (Fish Embeddings)\",\n",
    "        embedding_type=\"fish\",\n",
    "        run_ids=[f\"fish_{i}\" for i in range(10)],\n",
    "    ),\n",
    "    ResultConfig(\n",
    "        name=\"Baseline (LLM Embeddings)\",\n",
    "        embedding_type=\"llm\",\n",
    "        run_ids=range(10),\n",
    "        pipeline=\"fish\",\n",
    "    )\n",
    "]\n",
    "\n",
    "performance_dfs, utility_dfs, algo_assignments = show_results(result_configs, method=METHOD)\n",
    "\n",
    "for name in performance_dfs.keys():\n",
    "    print(name)\n",
    "    print(performance_dfs[name].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_sorted_utility_distributions(utility_dfs[\"LLM Embeddings\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plot_candidate_distribution_stacked(algo_assignments[\"LLM Embeddings\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
